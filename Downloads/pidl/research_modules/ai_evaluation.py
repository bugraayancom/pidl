"""
AI Kod DeÄŸerlendirme Formu
KatÄ±lÄ±mcÄ±larÄ±n AI'nÄ±n Ã¼rettiÄŸi kodu deÄŸerlendirmesi
"""

import streamlit as st
from typing import Dict, Any


class AIEvaluationForm:
    """AI Kod DeÄŸerlendirme Formu"""

    EVALUATION_DIMENSIONS = {
        "code_understandability": {
            "title": "Kod AnlaÅŸÄ±lÄ±rlÄ±ÄŸÄ±",
            "question": "AI'nÄ±n Ã¼rettiÄŸi kod ne kadar anlaÅŸÄ±lÄ±r?",
            "low_label": "HiÃ§ AnlaÅŸÄ±lmÄ±yor",
            "high_label": "Ã‡ok AnlaÅŸÄ±lÄ±r"
        },
        "explanation_quality": {
            "title": "AÃ§Ä±klama Kalitesi",
            "question": "AI'nÄ±n verdiÄŸi aÃ§Ä±klamalar ne kadar yeterli?",
            "low_label": "Yetersiz",
            "high_label": "MÃ¼kemmel"
        },
        "educational_value": {
            "title": "Ã–ÄŸreticilik",
            "question": "Bu koddan ne kadar ÅŸey Ã¶ÄŸrendiniz?",
            "low_label": "HiÃ§bir Åey",
            "high_label": "Ã‡ok Åey"
        },
        "perceived_code_quality": {
            "title": "Kod Kalitesi (Tahmini)",
            "question": "Kodun kaliteli gÃ¶rÃ¼ndÃ¼ÄŸÃ¼nÃ¼ dÃ¼ÅŸÃ¼nÃ¼yor musunuz?",
            "low_label": "Ã‡ok KÃ¶tÃ¼",
            "high_label": "Ã‡ok Ä°yi"
        },
        "perceived_security": {
            "title": "GÃ¼venlik",
            "question": "Kod gÃ¼venli gÃ¶rÃ¼nÃ¼yor mu?",
            "low_label": "GÃ¼vensiz",
            "high_label": "Ã‡ok GÃ¼venli"
        }
    }

    @staticmethod
    def show(ai_type: str = "AI") -> Dict[str, Any]:
        """
        AI deÄŸerlendirme formunu gÃ¶ster

        Args:
            ai_type: "Similar" veya "Complementary"

        Returns:
            DeÄŸerlendirme sonuÃ§larÄ±
        """
        st.markdown(f"### ğŸ¤– {ai_type} AI DeÄŸerlendirmesi")
        st.info("LÃ¼tfen AI'nÄ±n Ã¼rettiÄŸi kodu deÄŸerlendirin:")

        responses = {}

        # Likert skorlar
        for key, dimension in AIEvaluationForm.EVALUATION_DIMENSIONS.items():
            st.markdown(f"#### {dimension['title']}")
            st.markdown(f"*{dimension['question']}*")

            col1, col2, col3 = st.columns([2, 6, 2])

            with col1:
                st.caption(dimension['low_label'])

            with col2:
                score = st.slider(
                    label="",
                    min_value=1,
                    max_value=10,
                    value=5,
                    key=f"ai_eval_{key}",
                    label_visibility="collapsed"
                )
                responses[key] = score

            with col3:
                st.caption(dimension['high_label'])

            st.markdown("---")

        # AÃ§Ä±k uÃ§lu sorular
        st.markdown("#### ğŸ’­ AÃ§Ä±k UÃ§lu DeÄŸerlendirme")

        best_aspect = st.text_area(
            "Bu AI'nÄ±n en iyi yÃ¶nÃ¼ neydi?",
            placeholder="Ã–rn: AÃ§Ä±klamalarÄ± Ã§ok detaylÄ±ydÄ±, kod Ã§ok temizdi, gÃ¼venlik konularÄ±na dikkat ediyordu...",
            key="ai_eval_best_aspect",
            height=100
        )
        responses['best_aspect'] = best_aspect

        improvement_needed = st.text_area(
            "Bu AI'nÄ±n geliÅŸtirilmesi gereken yÃ¶nÃ¼ neydi?",
            placeholder="Ã–rn: Daha fazla yorum ekleyebilirdi, aÃ§Ä±klamalarÄ± karmaÅŸÄ±ktÄ±, bazÄ± edge case'leri atlÄ±yordu...",
            key="ai_eval_improvement",
            height=100
        )
        responses['improvement_needed'] = improvement_needed

        # Ã–zet metrikler
        st.markdown("### ğŸ“Š DeÄŸerlendirme Ã–zeti")

        numeric_scores = {k: v for k, v in responses.items() if isinstance(v, int)}
        avg_score = sum(numeric_scores.values()) / len(numeric_scores) if numeric_scores else 0

        col1, col2, col3 = st.columns(3)

        with col1:
            st.metric("Ortalama Puan", f"{avg_score:.1f}/10")

        with col2:
            max_score = max(numeric_scores.items(), key=lambda x: x[1])
            st.metric(
                "En YÃ¼ksek",
                AIEvaluationForm.EVALUATION_DIMENSIONS[max_score[0]]['title'][:15]
            )

        with col3:
            min_score = min(numeric_scores.items(), key=lambda x: x[1])
            st.metric(
                "En DÃ¼ÅŸÃ¼k",
                AIEvaluationForm.EVALUATION_DIMENSIONS[min_score[0]]['title'][:15]
            )

        return responses

    @staticmethod
    def get_overall_rating(responses: Dict[str, Any]) -> str:
        """Genel deÄŸerlendirme"""
        numeric_scores = {k: v for k, v in responses.items() if isinstance(v, int)}
        avg_score = sum(numeric_scores.values()) / len(numeric_scores) if numeric_scores else 0

        if avg_score >= 8:
            return "MÃ¼kemmel"
        elif avg_score >= 6:
            return "Ä°yi"
        elif avg_score >= 4:
            return "Orta"
        else:
            return "GeliÅŸtirilmeli"
